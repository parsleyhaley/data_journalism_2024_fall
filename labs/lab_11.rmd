---
title: "lab_11"
author: "Derek Willis"
date: "2024-11-09"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## You will need

-   Our usual libraries for working with data, including dates and column names, plus rvest.

## Load libraries and establish settings

**Task** Create a codeblock and load appropriate packages and settings for this lab.

```{r}
library(tidyverse)
library(rvest)
library(janitor)
library(lubridate)
```


Let's get to scraping. We'll be working on collecting information about Maryland election results, and then we'll grab some congressional press releases. For Maryland races, we'll focus on Board of Education races using this CNS story as a guide: https://cnsmaryland.org/2024/11/08/md-conservatives-make-gains-in-school-board-races/. You should read it.

## Questions

**Q1**. Write code to scrape the table of unofficial results from Frederick County's Board of Education races (https://elections.maryland.gov/elections/2024/general_Results/gen_results_2024_by_county_11.html), producing a dataframe that contains the results of that race for each candidate and removing the total. You'll need to identify which table on the page contains the BOE results. All numbers should actually be numbers, including the percentage. Then make a bar chart of the results, noting that the top 3 candidates win.

**A1**

```{r}
school_board <- "https://elections.maryland.gov/elections/2024/general_Results/gen_results_2024_by_county_11.html"
results <- school_board |>
  read_html() |>
  html_table()

results <- results[[9]]

results_clean <- results |> 
mutate(`Early Voting` = as.numeric(gsub(",","", `Early Voting`))) |>
mutate(`Election Day` = as.numeric(gsub(",","", `Election Day`)))  |> 
mutate(`Provisional` = as.numeric(gsub(",","", `Provisional`))) |> 
 mutate(`Total` = as.numeric(gsub(",","", `Total`))) |> 
   mutate(`Mail-In Ballot` = as.numeric(gsub(",","", `Mail-In Ballot`))) |> 
 mutate(`Percentage` = as.numeric(gsub("%","", `Percentage`)) ) 

```
```{r}
results_clean |> 
  slice(-9) |>
  ggplot() + 
  geom_bar(aes(x=reorder(Name, Total), weight=Total)) +
  coord_flip() +
  theme_minimal() +
labs(
    title= "Brennan, Moiner Lead in Tight Frederick County School Board Race",
    subtitle= "The top three candidates will secure spots on the school board", 
    x = "Candidate Name",
    y = "Number of Votes",
    caption = "source: Maryland State Board of Elections")
```


**Q2** Next, let's scrape the list of press releases from Maryland's Office of the State Prosecutor, <https://osp.maryland.gov/category/press-releases/>. This isn't a table, so you'll need to use `html_elements()` and your browser's inspector and do some clean up on the results. The result should be a dataframe with three columns: title, url and date. HINT: you can extract the date from the title using lubridate OR you can use the `separate` function.

You should have 10 releases when finished, not 20.

Then, write code that finds the most recent release with the word "Campaign" in the title. What election does it refer to? 

**A2** The most recent release with the word "Campaign" in it is "John King for Governor Campaign Cited for Authority Line Violations," published April 3, 2024. It refers to citations for actions by the John King campaign during the 2022 Maryland Primary Election.



```{r}
#save url
press_url <- "https://osp.maryland.gov/category/press-releases/" 

#save html as variable
prosecutor_press <- press_url |>
  read_html()

#isolate 'al' tags 
prosecutor_tag <- prosecutor_press |> html_elements("h2 a") 


#make dataframe using html variable
prosecutor_urls <- tibble(
  name = prosecutor_tag |>  html_text(trim = TRUE),
  url = prosecutor_tag |> html_attr("href"), 
)

#add in data and clean up
prosecutor_urls <- prosecutor_urls |> separate(col=name, into=c('date', 'title'), sep=':')

prosecutor_urls <- prosecutor_urls |> 
  mutate(date=mdy(date))

prosecutor_urls |> filter(str_detect(title, "Campaign")) |> 
  arrange(desc(date))


```


**Q3** Sen. Ben Cardin, D-Maryland, has posted hundreds of press releases at <https://www.cardin.senate.gov/?post_type=press-releases>. It would be great to have all of them in a dataframe that has the following columns: date, title and url.

To do this, you will need to scrape the page's html and save that to a variable, and *then* extract the dates, titles and urls into *separate* dataframes using html_elements(). We turn a list into a dataframe using `as_tibble()`.

At the end, you'll have three dataframes that you want to combine into a single dataframe. When we want to combine the rows of identical dataframes, we used `bind_rows()`. If you were combining columns instead of rows, there's a similar function. Use it to put all of the dataframes together into a single one. You are combining columns, not rows.

When you're done, rename the columns so they make sense, then make sure the date column is an actual date.

Finally, tell me what questions you could ask of this data, and what other information about it would be useful to have. Be creative.


**A3**

Q: What updates and actions involving Israel does Cardin highlight via his press releases?

Because they are featured on Cardin's site and produced by his staff, these press releases tell us about how Cardin wants his constitutants, and the world at large, to see him, and about the issues and actions that are important to him.

For example, you could use this data to identify and inspect Cardin's press releases that mention Israel by filtering for the word "Israel" used in the press release title. Israel might be particularly interesting because Cardin has a long history of advocacy for Israel, and because, as of September 2023, he is the chair of the Senate Foreign Relations Committee, so his beliefs are especially relevant to the U.S.'s foreign policy. You could add a time component into this query as well, for example: what has Cardin posted about Israel since October 7, 2023? How does the number of posts since that date compare to the number of posts before that date?

You could run the search above using different search terms to find Cardin's posts or viewpoints about a number of issues -- "SCOTUS," or "LGBT," or "Infrastructure," for example. 

I think the time component is also interesting, and could be used to compare Cardin's press releases with other data frames, because the press releases are usually reactions to or descriptions of specific events, and are released on the day of or shortly thereafter. For example, what if we compared Cardin's press releases with those of several other senators, some democrats and some republicans, and with a dataframe of NYT headlines (maybe the top 5 headlines per day, or the top headlines concerning a certain topic; some parameter like that) all organized by date. What events do the senators choose to respond to? Are there patterns among parties?

I think it might be helpful to include the two lines of text that appear below each title in the dataframe. Since it's only two lines of text I don't think it would make the dataframe too unwieldy/hard to read, but those lines of text sometimes contain a lot more information than the title-- basically the lead for the press release. And the structure of those lines makes it easier to search for information. For example, when Cardin posts about collaborating with other lawmakers, he usually puts his name and the last name of those lawmakers in the title-- for example, "Cardin, Rosen, Cramer, Blumenthal, Rubio, Introduce Bipartisan Bill to Reauthorize Never Again Education Act Passes the Senate." But, in the description that appears below the title, Cardin almost always uses the word "join" to describe collaborative actions. So if you're searching just the titles, you'd have to search the names of specific lawmakers to learn about collaboration, but if you had the description, you could use the word "join" to find most (although not all) of Cardin's posts about collaborating with other lawmakers.


```{r}
#save url
cardin_url <- "https://www.cardin.senate.gov/?post_type=press-releases" 

#save html as variable
cardin_press <- cardin_url |>
  read_html()

#isolate tags 
#tag 1: date
cardin_date <- cardin_press |> html_elements("h5") 

#tag 2: title
cardin_title <- cardin_press |> html_elements("h3")

#tag 3: url
cardin_url <- cardin_press |> html_elements("h3 a")


#make dataframes using html variable
date_df <- tibble(
  date_cardin = cardin_date |> html_text(trim = TRUE))

title_df <- tibble(
 title_cardin = cardin_title |> html_text(trim = TRUE))

url_df <- tibble(
  url_cardin = cardin_url |> html_attr("href")
)

#combine data and clean up

clean_cardin <- date_df |> bind_cols(title_df, url_df)

colnames(clean_cardin)[1] = "date"
colnames(clean_cardin)[2] = "title"
colnames(clean_cardin)[3] = "url"

clean_cardin <- clean_cardin |> 
  mutate(date=mdy(date))


```

